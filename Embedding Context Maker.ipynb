{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakrutpatel/Context-RCNN-Tortoises/blob/main/Embedding%20Context%20Maker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDq5Cbc-nhDc"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M01mKzMLK0sL"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.8\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U13xVug-dVsR"
      },
      "outputs": [],
      "source": [
        "!pip install python-snappy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4AfdpdJVseS"
      },
      "outputs": [],
      "source": [
        "!pip install apache-beam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MidBYdl47zyb"
      },
      "outputs": [],
      "source": [
        "!pip install pycocotools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UehmL1DnhDf"
      },
      "source": [
        "#### Download and install TensorFlow framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5x9DnFprzP4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_Agbj3g8HHi"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIVxNykopnHP"
      },
      "outputs": [],
      "source": [
        "%cd models/research/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0JsvXhL8VFn"
      },
      "outputs": [],
      "source": [
        "!python object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr8vgFV5nhDg"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36ieYqAB9PUr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import pathlib\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxen_qpJ9R65"
      },
      "outputs": [],
      "source": [
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXpXhpMU9UeX"
      },
      "outputs": [],
      "source": [
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgP7UH_ynhDg"
      },
      "source": [
        "##### Optional - Not needed if your images are in tfrecords format with annotations and timestamp field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T6flGumNd_L"
      },
      "outputs": [],
      "source": [
        "#@title Optional, if you're starting for Json COCO format files { display-mode: \"both\" }\n",
        "!python object_detection/dataset_tools/context_rcnn/create_cococameratraps_tfexample_main.py \\\n",
        "  --alsologtostderr \\\n",
        "  --output_tfrecord_prefix=\"/content/tfrecords_valid/\" \\\n",
        "  --image_directory=\"/content/models/research/train\" \\\n",
        "  --input_annotations_file=\"/content/models/research/train/_annotations.coco.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVXk_o1nUa53"
      },
      "outputs": [],
      "source": [
        "#@title Optional, if you don't have bounding box for your data { display-mode: \"both\" }\n",
        "!python object_detection/dataset_tools/context_rcnn/generate_detection_data.py \\\n",
        "  --alsologtostderr \\\n",
        "  --detection_input_tfrecord=\"/content/tfrecords_valid/\" \\\n",
        "  --detection_output_tfrecord=\"/content/tfrecords_new\" \\\n",
        "  --detection_model_dir=\"/content/drive/MyDrive/4/saved_model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDCCDLP2nhDh"
      },
      "source": [
        "#### Generate Embddings for training and testing tfrecords file using Faster RCNN **input_type tfexample** model\n",
        "\n",
        "The input node must of type tf.Example proto.\n",
        "Reference - [Generate Embedding](https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/context_rcnn/generate_embedding_data.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO-sN_HOnhDh"
      },
      "outputs": [],
      "source": [
        "#Input parameters\n",
        "faster_rcnn_model_path = \"/content/drive/MyDrive/Faster RCNN/Faster_RCNN_SS1_tfexample/saved_model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwJ2DB1mzH2T"
      },
      "outputs": [],
      "source": [
        "#Update path as required\n",
        "!python object_detection/dataset_tools/context_rcnn/generate_embedding_data.py \\\n",
        "    --alsologtostderr \\\n",
        "    --embedding_input_tfrecord=\"/content/drive/MyDrive/B004_long_term_tfrecords/B004_context_rcnn_memory_train\" \\\n",
        "    --embedding_output_tfrecord=\"/content/B004_context_rcnn_memory_train_embedding\" \\\n",
        "    --embedding_model_dir=faster_rcnn_model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfaaKv3zR4YA"
      },
      "outputs": [],
      "source": [
        "!python object_detection/dataset_tools/context_rcnn/generate_embedding_data.py \\\n",
        "    --alsologtostderr \\\n",
        "    --embedding_input_tfrecord=\"/content/drive/MyDrive/B004_long_term_tfrecords/B004_context_rcnn_memory_test\" \\\n",
        "    --embedding_output_tfrecord=\"/content/B004_context_rcnn_memory_test_embedding\" \\\n",
        "    --embedding_model_dir=faster_rcnn_model_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImHBd5UWnhDh"
      },
      "source": [
        "##### Optional - Copy the resulting files to a permanent storage location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQnkh_PzSadZ"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/B004_context_rcnn_memory_train_embedding-00000-of-00001\" \"/content/drive/MyDrive/B004_long_term_tfrecords/B004_context_rcnn_memory_train_embedding-00001-of-00001\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOmAx_F2Sl3f"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/B004_context_rcnn_memory_test_embedding-00000-of-00001\" \"/content/drive/MyDrive/B004_long_term_tfrecords/B004_context_rcnn_memory_test_embedding-00001-of-00001\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_VQ8FihnhDh"
      },
      "source": [
        "#### Add context for training and testing tfrecords file with embeddings (The files made in the steps above)\n",
        "\n",
        "This tool groups images containing bounding boxes and embedded context features\n",
        "by a key, either `image/location` or `image/seq_id`, and time horizon,\n",
        "then uses these groups to build up a contextual memory bank from the embedded\n",
        "context features from each image in the group and adds that context to the\n",
        "output tf.Examples for each image in the group.\n",
        "\n",
        "See reference [Add Context](https://github.com/tensorflow/models/blob/master/research/object_detection/dataset_tools/context_rcnn/add_context_to_examples.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WALC0tzaBpva"
      },
      "outputs": [],
      "source": [
        "!python object_detection/dataset_tools/context_rcnn/add_context_to_examples.py \\\n",
        "  --input_tfrecord=\"/content/B004_context_rcnn_memory_train_embedding-00000-of-00001\" \\\n",
        "  --output_tfrecord=\"/content/B004_context_rcnn_memory_train_embedding_with_context\" \\\n",
        "  --sequence_key image/seq_id \\\n",
        "  --time_horizon month \\\n",
        "  --output_type tf_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSecs6JVTUd2"
      },
      "outputs": [],
      "source": [
        "!python object_detection/dataset_tools/context_rcnn/add_context_to_examples.py \\\n",
        "  --input_tfrecord=\"/content/B004_context_rcnn_memory_test_embedding-00000-of-00001\" \\\n",
        "  --output_tfrecord=\"/content/B004_context_rcnn_memory_test_embedding_with_context\" \\\n",
        "  --sequence_key image/seq_id \\\n",
        "  --time_horizon month \\\n",
        "  --output_type tf_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8l5qy_4nhDi"
      },
      "source": [
        "##### Copy the resulting files to a permanent storage location to be used later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFDL0XUaUkEu"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/B004_context_rcnn_memory_train_embedding_with_context-00000-of-00001\" \"/content/drive/MyDrive/B004_long_term_tfrecords/B004_context_rcnn_memory_train_embedding_with_context-00001-of-00001\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "481Oi_06VP-B"
      },
      "outputs": [],
      "source": [
        "!cp \"/content/B004_context_rcnn_memory_test_embedding_with_context-00000-of-00001\" \"/content/drive/MyDrive/B004_long_term_tfrecords/B004_context_rcnn_memory_test_embedding_with_context-00001-of-00001\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}