{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakrutpatel/Context-RCNN-Tortoises/blob/main/Faster_RCNN_Training_on_Serengeti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dW2W17o-p7SX"
      },
      "outputs": [],
      "source": [
        "# Make sure tensorflow gpu version 1.15 is installed as there seems to be compatibility issues between tensorflow and numpy with other versions that causes an error while training\n",
        "!pip install tensorflow_gpu==1.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnuFwJerdQFP"
      },
      "source": [
        "## Install other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0y62xfiOCSJg"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.19.5\n",
        "!pip uninstall -y pycocotools\n",
        "!pip install pycocotools --no-binary pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Xh3JAzyQEoz"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1LTBIdRYfy8"
      },
      "source": [
        "##Restart runtime as this point so we have compatible tensorflow_gpu and numpy versions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "#### Install required packages and download Tensorflow Framework from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecpHEnka8Kix"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools tf_slim\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaC97k61dQFS"
      },
      "source": [
        "## Optional - If working on Colab, install colab package and mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydc5HamQ4hSd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "This example uses pre-annotated gopher tortoise dataset hosted on my roboflow page.\n",
        "\n",
        "Because we need one TFRecord file for our training data, and one TFRecord file for our test data, we'll create two separate datasets in Roboflow and generate one set of TFRecords for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb_FMcfnSbRZ"
      },
      "outputs": [],
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/4DemUlSMP4?key=OPFgu1ApfM\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36Pj-_lwdQFT"
      },
      "source": [
        "**Make sure train and test folders contain '.pbtxt' and '.tfrecord' file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "outputs": [],
      "source": [
        "# NOTE: Update these TFRecord names to your respective folders and names\n",
        "test_record_fname = '/content/drive/MyDrive/B004_context_rcnn_memory_test'\n",
        "train_record_fname = '/content/drive/MyDrive/B004_context_rcnn_memory_train'\n",
        "label_map_pbtxt_fname = '/content/tortoise_label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download base model\n",
        "\n",
        "We will use Faster R-CNN ResNet 101 trained on serengeti data as our starting point. Transfer Learning will allow us to modify existing weights and configurations to work with our custom dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSBg1blhXzRX"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!wget \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_snapshot_serengeti_2020_06_10.tar.gz\"\n",
        "!tar -xvf \"faster_rcnn_resnet101_snapshot_serengeti_2020_06_10.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnR5SyR_ZQeI"
      },
      "outputs": [],
      "source": [
        "#Modify path as required\n",
        "pipeline_fname = \"/content/faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/pipeline.config\"\n",
        "fine_tune_checkpoint = \"/content/faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/model.ckpt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBxZiFq1dQFU"
      },
      "outputs": [],
      "source": [
        "#Define training parameters\n",
        "\n",
        "num_steps = 4000\n",
        "batch_size = 4\n",
        "num_eval_steps = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "outputs": [],
      "source": [
        "#Define variable pipeline_file here, if you want to use a custom configuration from https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs\n",
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8iFP5NyZqHF"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JnE3f51dQFU"
      },
      "source": [
        "#### Attention - At this point make changes to the config file to work with your dataset (number of classes, learning rates, image aspect ratios etc).\n",
        "\n",
        "#### The cells provided below work for the most part but are unreliable sometimes and need modification on a case by case basis.\n",
        "\n",
        "#### Add these lines in the config file before training, they play an important role in creating context and embeddings required for context rcnn\n",
        "from_detection_checkpoint: true\n",
        "load_all_detection_checkpoint_vars: true\n",
        "fine_tune_checkpoint_type: \"detection\"\n",
        "\n",
        "\n",
        "Take a look at lines [108-131](https://github.com/prakrutpatel/Context-RCNN-Tortoises/blob/main/Examples/Faster%20RCNN.config) for reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG1nCNpUXcRU"
      },
      "outputs": [],
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjtCbLF2i0wI"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "\n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH0MEEanocn6"
      },
      "outputs": [],
      "source": [
        "!cat {pipeline_fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "outputs": [],
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8k0RGRWdQFV"
      },
      "source": [
        "For some reason installing lvis may cause problems with tensorflow. If this happens rerun all the pip install lines at the start of this notebook (without restarting session).\n",
        "\n",
        "Do not rerun this cell after doing that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC7_syR1SJ9F"
      },
      "outputs": [],
      "source": [
        "!pip install lvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjDHjhKQofT5"
      },
      "outputs": [],
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP-tUdtnRybs"
      },
      "outputs": [],
      "source": [
        "!ls {model_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snh4phr3dQFV"
      },
      "source": [
        "## Review training logs and tensorboard for metric and evaluation, redo training by changing configuration as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4psLp5RQmg5"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHoP90pUyKSq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj_RClucdQFW"
      },
      "source": [
        "#### We need to export this model twice.\n",
        "1. With input_type image_tensor - Used when we pass in an image converted into 4-D tensor\n",
        "2. With input_type tf_example - Used when we pass a 1-D string tensor containing serialized TFExample protos, used to create embeddings and context.\n",
        "\n",
        "\n",
        "Read more at [Export Inference Graph](https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz4FRxpFdQFW"
      },
      "outputs": [],
      "source": [
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path {pipeline_fname} \\\n",
        "    --output_directory \"/content/Faster_RCNN_SS_imagetensor\" \\\n",
        "    --trained_checkpoint_prefix {last_model_path} \\\n",
        "    --additional_output_tensor_names detection_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NY1kM4aOdQFW"
      },
      "outputs": [],
      "source": [
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type tf_example \\\n",
        "    --pipeline_config_path {pipeline_fname} \\\n",
        "    --output_directory \"/content/Faster_RCNN_SS_tfexample\" \\\n",
        "    --trained_checkpoint_prefix {last_model_path} \\\n",
        "    --additional_output_tensor_names detection_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCkdaF4MZwbF"
      },
      "source": [
        "Exported model is located at '/content/{output directory name}'\n",
        "Save as zip for future use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QVSVKlAKHca"
      },
      "outputs": [],
      "source": [
        "!zip -r \"/content/Faster_RCNN_SS_imagetensor.zip\" \"/content/Faster_RCNN_SS_imagetensor\"\n",
        "!zip -r \"/content/Faster_RCNN_SS_tfexample.zip\" \"/content/Faster_RCNN_SS_tfexample\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBZTWuyFdQFZ"
      },
      "source": [
        "#### Recommended - Save a copy of the zip file on the cloud and locally"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FIqnjbWYsuQw",
        "2FKFq8RXs6bs",
        "MFyCeiBb9BbS"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}