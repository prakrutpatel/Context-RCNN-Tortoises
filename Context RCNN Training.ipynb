{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakrutpatel/Context-RCNN-Tortoises/blob/main/Context%20RCNN%20Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69AihZ-HujXf"
      },
      "source": [
        "## Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dW2W17o-p7SX"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_gpu==1.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0y62xfiOCSJg"
      },
      "outputs": [],
      "source": [
        "!pip install numpy==1.19.5\n",
        "!pip uninstall -y pycocotools\n",
        "!pip install pycocotools --no-binary pycocotools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO4Ain0RP5Im"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "## Download and install TensorFlow framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecpHEnka8Kix"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools tf_slim\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t2k4uCLujXj"
      },
      "source": [
        "#### Optionally mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qssoxuv0pS_E"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download base model\n",
        "\n",
        "#### For this example we use Context R-CNN Resnet101 Model trained on Serengeti dataset\n",
        "#### Follow intructions from Faster R-CNN training example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSBg1blhXzRX"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!wget \"http://download.tensorflow.org/models/object_detection/context_rcnn_resnet101_snapshot_serengeti_2020_06_10.tar.gz\"\n",
        "!tar -xvf \"context_rcnn_resnet101_snapshot_serengeti_2020_06_10.tar.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnR5SyR_ZQeI"
      },
      "outputs": [],
      "source": [
        "pipeline_fname = \"/content/context_rcnn_resnet101_snapshot_serengeti_2020_06_10/pipeline.config\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHnxlfRznPP3"
      },
      "outputs": [],
      "source": [
        "fine_tune_checkpoint = \"/content/context_rcnn_resnet101_snapshot_serengeti_2020_06_10/model.ckpt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline\n",
        "\n",
        "#### Follow intructions from Faster R-CNN training example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8iFP5NyZqHF"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDJO1I4_ujXm"
      },
      "source": [
        "#### Attention - Make changes to the config file to work with your dataset (number of classes, learning rates, image aspect ratios etc).\n",
        "\n",
        "\n",
        "Take a look at [Context RCNN Config](https://github.com/prakrutpatel/Context-RCNN-Tortoises/blob/main/Examples/Context%20RCNN.config) for reference\n",
        "\n",
        "Most importantly change these fields to match your example/environment:\n",
        "1. num_classes\n",
        "2. batch_size\n",
        "3. fine_tune_checkpoint - change to fine_tune_checkpoint variable value\n",
        "4. num_steps\n",
        "5. label_map_path - you can use .pbtxt from faster rcnn training example\n",
        "6. tf_record_input_reader\n",
        "    - input_path: Location of the training tfrecord file made from Embedding+Context Maker file. Training Tfrecord with embedding and context\n",
        "7. eval_input_reader\n",
        "    - tf_record_input_reader\n",
        "        - input_path: Location of the testing tfrecord file made from Embedding+Context Maker file. Testing Tfrecord with embedding and context\n",
        "\n",
        "Take a look at the reference example config file above. It will give you some insight as to which parameters needs to be changed.\n",
        "Once you get a better understanding of the training, you can modify the learning rates and steps config for optimal training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GH0MEEanocn6"
      },
      "outputs": [],
      "source": [
        "!cat {pipeline_fname}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "outputs": [],
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P2L86yfujXm"
      },
      "source": [
        "For some reason installing lvis may cause problems with tensorflow. If this happens rerun all the pip install lines at the start of this notebook (without restarting session).\n",
        "\n",
        "Do not rerun this cell after doing that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nC7_syR1SJ9F"
      },
      "outputs": [],
      "source": [
        "!pip install lvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjDHjhKQofT5"
      },
      "outputs": [],
      "source": [
        "#Change steps and eval steps to match config file\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path=\"/content/models/research/object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti.config\" \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=4000 \\\n",
        "    --num_eval_steps=50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KP-tUdtnRybs"
      },
      "outputs": [],
      "source": [
        "!ls {model_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "IXwS-5XHQ4oq",
        "outputId": "c202727a-e9d1-4b6d-ca4e-39ca6347ad97"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir \"/content/models/research/training/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHoP90pUyKSq"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "\n",
        "#input_type image_tensor is the only one required as from now on only images will be passed to the model\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --input_shape 1,-1,-1,3 \\\n",
        "    --pipeline_config_path \"/content/models/research/object_detection/samples/configs/context_rcnn_resnet101_snapshot_serengeti.config\" \\\n",
        "    --trained_checkpoint_prefix {last_model_path} \\\n",
        "    --output_directory \"/content/Context_RCNN_SS1_trained\" \\\n",
        "    --use_side_inputs True \\\n",
        "    --side_input_shapes 1,2000,2057/1 \\\n",
        "    --side_input_names context_features,valid_context_size \\\n",
        "    --side_input_types float,int\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxQBM2yliZEN"
      },
      "source": [
        "#### Zip the saved model directory and save the zip to permanent storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QVSVKlAKHca"
      },
      "outputs": [],
      "source": [
        "!zip -r \"/content/Context_RCNN_SS_trained_1.zip\" \"/content/Context_RCNN_SS_trained\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aikl7H77ufBE"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/Context_RCNN_SS1_trained\" \"/content/drive/MyDrive/experimental/Context_RCNN_SS1_trained\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FIqnjbWYsuQw",
        "2FKFq8RXs6bs",
        "MFyCeiBb9BbS"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}